{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Yield Analysis: Exploring Trends and Predictive Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Objective and Scope\n",
    "\n",
    "The objective of this project is to analyze the crop yield data of Rural Municipalities (RM) in Saskatchewan, Canada from 1938 to 2021. The dataset contains yield data for various crops, including Winter Wheat, Canola, Spring Wheat, Mustard, Durum, Sunflowers, Oats, Lentils, Peas, Barley, Fall Rye, Canary Seed, Spring Rye, Tame Hay, Flax, and Chickpeas.\n",
    "\n",
    "The scope of the project is to perform a thorough data analysis on the yield data, including data cleaning, exploration, and visualization. Machine learning techniques will be applied to develop models for predicting crop yields. The analysis will focus on identifying trends and patterns in the data and providing insights into factors that affect crop yields in different regions of Saskatchewan.\n",
    "\n",
    "The dataset covers crop yield data for 299 Rural Municipalities (RM) in Saskatchewan, Canada. The analysis will cover the entire range of years in the dataset, from 1938 to 2021."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Research questions and Hypotheses\n",
    "\n",
    "Research questions:\n",
    "\n",
    "* What is the overall trend in crop yields in Saskatchewan from 1938 to 2021?\n",
    "* Which crops have the highest and lowest yields in Saskatchewan, and how have these yields changed over time?\n",
    "* Are there any differences in crop yields between different regions of Saskatchewan?\n",
    "\n",
    "Hypotheses:\n",
    "\n",
    "* There is an overall increasing or decreasing trend in crop yields in Saskatchewan over time.\n",
    "* Certain crops may have higher or lower yields than others, and these yields may change at different rates over time.\n",
    "* There may be significant differences in crop yields between different regions of Saskatchewan."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description of the dataset and its sources"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Load Library*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (30, 20)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Description*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spacial dataset by reading 'RuralMunicipality/Rural Municipality.shp'\n",
    "gdf = gpd.read_file('RuralMunicipality/Rural Municipality.shp')\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdata = gdf.copy()\n",
    "gdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdata.rename(columns={\"RMNO\": \"RM\"}, inplace=True)\n",
    "gdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset by reading 'rm_crop_yields_1938_2021.csv' \n",
    "df = pd.read_csv('rm_crop_yields_1938_2021.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of orginial dataset, we will do all modifications on the copy.\n",
    "data = df.copy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the dataset.\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the first 5 rows of the dataset.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the last 5 rows of the dataset.\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of unique value for 'Year' and 'RM' column\n",
    "print('Year:' + str(data['Year'].nunique()))\n",
    "print('RM:' + str(data['RM'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show information of the dataset.\n",
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The dataset used for this project is named \"rm_crop_yields_1938_2021.csv\" and contains yield data for different crops grown in different RMs (Rural Municipalities) in Saskatchewan, Canada from 1938 to 2021. The dataset contains 25017 observations and 18 features. The features include the year and RM number along with the yield data for 16 different crops including Winter Wheat, Canola, Spring Wheat, Mustard, Durum, Sunflowers, Oats, Lentils, Peas, Barley, Fall Rye, Canary Seed, Spring Rye, Tame Hay, Flax, and Chickpeas.\n",
    "\n",
    "Out of the 16 crops, not all are present in every year for every RM, hence some of the yield values are missing. The data types of the features are either float64 or int64. The numerical features in the dataset represent yield data and are measured in bushels per acre (bu/acre).\n",
    "\n",
    "The time period covered by the dataset is from 1938 to 2021, giving a total of 84 years of data.\n",
    "\n",
    "Unfortunately, the source of this dataset is not specified, and we do not have any information regarding its origin or collection process. However, the dataset appears to be reliable and of high quality, and we will conduct a thorough analysis of the data to derive meaningful insights.\n",
    "\n",
    "It is important to note that this dataset covers crop yield data only for Saskatchewan, Canada and may not be generalizable to other regions or countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdata.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdata['RM'] = gdata['RM'].astype(int)\n",
    "gdata['RMNM'] = gdata['RMNM'].astype('string')\n",
    "gdata['PPID'] = gdata['PPID'].astype('string')\n",
    "gdata['EFFDT'] = gdata['EFFDT'].astype('string')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Data Cleaning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do summary statistics of the dataset. \n",
    "data.describe().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check missing values\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Imutate the missing values.*\n",
    "In our case, we have a large number of missing values in some columns, so dropping the missing values may result in significant data loss. Therefore, we will use imputation to fill in the missing values.\n",
    "\n",
    "There are different strategies for imputation, and we will use a simple strategy of filling in the missing values with the mean value of the corresponding column. We can use the fillna method to fill in the missing values with the mean value of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Check outliers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with 8 rows and 2 columns\n",
    "fig, axes = plt.subplots(nrows=8, ncols=2)\n",
    "\n",
    "# Loop through each crop and create a boxplot in the corresponding axis\n",
    "crops = list(data.columns[2:])\n",
    "for i, crop in enumerate(crops):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    sns.boxplot(x=data[crop], ax=axes[row, col], orient='v', color='lightblue')\n",
    "    axes[row, col].set_title(crop)\n",
    "    \n",
    "# Remove the empty subplot(s)\n",
    "if len(crops) % 2 != 0:\n",
    "    fig.delaxes(axes[-1, -1])\n",
    "    \n",
    "# Adjust the spacing between the subplots\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those box plots show clearly that most of columns have outliers exist. However, the analysis is focused on identifying trends and patterns in the data, it would be best to keep the outliers in the dataset. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Identify outliers using z-scores*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to identify outliers using z-scores\n",
    "def detect_outliers_zscore(data, threshold=3):\n",
    "    z_scores = np.abs((data - data.mean()) / data.std())\n",
    "    return z_scores > threshold\n",
    "\n",
    "# identify outliers for each column\n",
    "outliers = data.apply(detect_outliers_zscore)\n",
    "\n",
    "# count the number of outliers in each column\n",
    "outlier_counts = outliers.sum()\n",
    "\n",
    "# print the number of outliers for each column\n",
    "print(outlier_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are missing values for some crops: Winter Wheat has only 3037 non-null values out of 25017, Spring Rye has only 805 non-null values out of 25017, and Tame Hay has only 4205 non-null values out of 25017.\n",
    "* The mean yield for the different crops ranges from 1.18 (Tame Hay) to 1408.06 (Chickpeas), the standard deviation of the yield for the different crops ranges from 0.65 (Tame Hay) to 579.64 (Chickpeas).\n",
    "* For most crops, the median yield is close to the mean, indicating that the distribution is roughly symmetric.\n",
    "* There are some crops with a large difference between the mean and median yield, indicating that the distribution may be skewed. For example, Mustard has a mean yield of 844.19 and a median yield of 847, suggesting that the distribution may be slightly skewed to the left.\n",
    "* For some crops, such as Canary Seed and Chickpeas, the maximum yield is much higher than the 75th percentile, indicating the presence of outliers in the data.\n",
    "* Overall, the dataset appears to have a wide range of yield values, with some crops having high variability in yield and potential outliers that may need to be addressed during data cleaning and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate skewness and kurtosis for each column\n",
    "for col in data.columns[2:]:\n",
    "    skewness = skew(data[col])\n",
    "    kurt = kurtosis(data[col])\n",
    "    print(f\"{col} - Skewness: {skewness:.2f} Kurtosis: {kurt:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Data Exploration*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Univariate Analysis*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the columns with crop data\n",
    "crop_cols = data.columns[2:]\n",
    "\n",
    "# Create subplots with two plots in each row\n",
    "fig, axs = plt.subplots(len(crop_cols)//2 + 1, 2)\n",
    "\n",
    "# Flatten the axes array\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Loop through the crop columns and plot a histogram for each crop\n",
    "for i, col in enumerate(crop_cols):\n",
    "    ax = axs[i]\n",
    "    sns.histplot(data=data[col], ax=ax, kde=True)\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel('Yield')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Remove the unused subplots\n",
    "for ax in axs[len(crop_cols):]:\n",
    "    ax.remove()\n",
    "\n",
    "# Adjust the layout\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Draw scatter plots for the relationship between 'Year' and each crop.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 4x4 subplot grid for the plots\n",
    "fig, axs = plt.subplots(nrows=8, ncols=2)\n",
    "\n",
    "# Loop over the crops and create a scatterplot for each one\n",
    "for i, crop in enumerate(crops):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    axs[row, col].scatter(data['Year'], data[crop])\n",
    "    axs[row, col].set_title(crop)\n",
    "\n",
    "# Adjust the spacing between the plots and display the figure\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Draw scatter plots for the relationship between 'RM' and each crop.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 4x4 subplot grid for the plots\n",
    "fig, axs = plt.subplots(nrows=8, ncols=2)\n",
    "\n",
    "# Loop over the crops and create a scatterplot for each one\n",
    "for i, crop in enumerate(crops):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    axs[row, col].scatter(data['RM'], data[crop])\n",
    "    axs[row, col].set_title(crop)\n",
    "\n",
    "# Adjust the spacing between the plots and display the figure\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Bivariatie Analysis*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns\n",
    "crops = data.columns[2:]\n",
    "\n",
    "# Create a correlation matrix\n",
    "corr_matrix = data[crops].corr()\n",
    "\n",
    "# Visualize the correlation matrix as a heatmap\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### *TBD*\n",
    "In the case of 'Oats' and 'Spring Wheat', a strong positive relationship suggests that when the yield of 'Oats' is high in a particular year, the yield of 'Spring Wheat' is also likely to be high in that same year.\n",
    "\n",
    "There are a number of possible reasons for this positive relationship. For example, both crops might have similar environmental requirements, such as soil type, temperature, or precipitation, which could affect their yields in similar ways. Alternatively, farmers may have similar planting, fertilization, or harvesting practices for both crops, which could also contribute to the observed relationship. It's also possible that there are other unmeasured factors that affect both crops, such as pests or diseases, that are driving the relationship."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Data Transformation* \n",
    "Before moving to the next stage, we standardized the data by scaling the values of the crop yield data between 0 and 1. This was done to ensure that all features have equal weightage in our machine learning model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Standardization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a StandardScaler object\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# fit and transform the data using the scaler\n",
    "data_standardized = standard_scaler.fit_transform(data)\n",
    "\n",
    "data_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.info(data_standardized)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Normalization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a MinMaxScaler object\n",
    "normalize_scaler = MinMaxScaler()\n",
    "\n",
    "# fit and transform the standardized dataset using the scaler object\n",
    "data_normalized = pd.DataFrame(normalize_scaler.fit_transform(data_standardized), columns=data.columns)\n",
    "\n",
    "# display the normalized dataset\n",
    "data_normalized"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Data Visualization*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Summarize the total yield of crops in each Rural Municipal*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TotalYield'] = data.iloc[:,2:].sum(axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtByYear = data.groupby('Year').sum()\n",
    "dtByYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfByRM = data.groupby('RM').sum()\n",
    "dfByRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfByRM_merged = dfByRM.merge(gdata, how='inner', on='RM')\n",
    "dfByRM_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfByRM_merged_gdata = gpd.GeoDataFrame(dfByRM_merged)\n",
    "# Plot choropleth map\n",
    "fig, ax = plt.subplots()\n",
    "dfByRM_merged_gdata.plot(column='TotalYield', cmap='YlGnBu', legend=True, ax=ax)\n",
    "ax.set_title('Crop Yield by RM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfByRM_merged_gdata.explore(\n",
    "    column='TotalYield',\n",
    "    cmap='inferno'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of crop names\n",
    "crop_names = list(data_normalized.columns)[2:]\n",
    "\n",
    "# set up the plot\n",
    "fig, axs = plt.subplots(8, 2)\n",
    "\n",
    "# Loop through the crops and create a line plot for each one\n",
    "for i, crop in enumerate(crop_names):\n",
    "    # Create a subplot for each crop, with two crops per row\n",
    "    plt.subplot(8, 2, i+1)\n",
    "    \n",
    "    # Set the title and axis labels\n",
    "    plt.title(crop)\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Yield')\n",
    "    \n",
    "    # Plot the line plot for the crop\n",
    "    sns.lineplot(x='Year', y=crop, data=data_normalized)\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the columns with crop data\n",
    "crop_cols = data_normalized.columns[2:]\n",
    "\n",
    "# Create subplots with two plots in each row\n",
    "fig, axs = plt.subplots(len(crop_cols)//2 + 1, 2)\n",
    "\n",
    "# Flatten the axes array\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Loop through the crop columns and plot a histogram for each crop\n",
    "for i, col in enumerate(crop_cols):\n",
    "    ax = axs[i]\n",
    "    sns.histplot(data=data_normalized[col], ax=ax, kde=True)\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel('Yield')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Remove the unused subplots\n",
    "for ax in axs[len(crop_cols):]:\n",
    "    ax.remove()\n",
    "\n",
    "# Adjust the layout\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns\n",
    "numeric_cols = data_normalized.columns[2:]\n",
    "\n",
    "# Create a correlation matrix\n",
    "corr_matrix = data_normalized[numeric_cols].corr()\n",
    "\n",
    "# Visualize the correlation matrix as a heatmap\n",
    "sns.heatmap(corr_matrix, cmap='YlOrRd', annot=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Feature Engineering*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data_by_year = data_normalized.groupby('Year', as_index=False).mean()\n",
    "scaled_data_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=scaled_data_by_year[scaled_data_by_year.columns[2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=scaled_data_by_year['Barley'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=scaled_data_by_year['Canola'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Machine Learning Model Development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Model Selection*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Series Analysis: Since you only have crop yield data and no other relevant features, time series analysis would be a suitable approach to predict crop yields over time. You can use techniques like ARIMA, SARIMA, or LSTM to predict the yield of a specific crop over a period of time.\n",
    "\n",
    "Clustering: Since you have yield data for 16 crops, you can use clustering techniques to group the crops that have similar yield patterns. This can help in identifying the factors that are contributing to the yield of each group of crops and thus, optimize the crop yield in the future."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Model Training and Testing - Time Series Analysis*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_name = 'Canola'\n",
    "# Define the order of the ARIMA model\n",
    "p = 1  # order of autoregressive term\n",
    "d = 0  # degree of differencing\n",
    "q = 1  # order of moving average term\n",
    "\n",
    "# Fit the ARIMA model to the data\n",
    "arima_model = ARIMA(data[crop_name], order=(p, d, q)).fit()\n",
    "\n",
    "# Print a summary of the model\n",
    "print(arima_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming you have already trained your ARIMA model and have it stored as `model`\n",
    "\n",
    "# make predictions for the next 5 time steps\n",
    "predictions = arima_model.forecast(steps=5)\n",
    "\n",
    "# print the predicted values\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the order of the ARIMA model\n",
    "p = 1  # order of autoregressive term\n",
    "d = 0  # degree of differencing\n",
    "q = 1  # order of moving average term\n",
    "\n",
    "# Fit the ARIMA model to the data\n",
    "arima_model_scaled = ARIMA(scaled_data_by_year[crop_name], order=(p, d, q)).fit()\n",
    "\n",
    "# Print a summary of the model\n",
    "print(arima_model_scaled.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming you have already trained your ARIMA model and have it stored as `model`\n",
    "\n",
    "# make predictions for the next 5 time steps\n",
    "predictions_scaled = arima_model_scaled.forecast(steps=5)\n",
    "\n",
    "# print the predicted values\n",
    "print(predictions_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data_by_year[crop_name].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the original data and the predicted values\n",
    "sns.lineplot(data = scaled_data_by_year[crop_name])\n",
    "sns.lineplot(data = predictions_scaled)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Crop Yield clustering using K-Means clustering*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the WCSS values\n",
    "wcss = []\n",
    "\n",
    "# Loop over different values of k and perform k-means clustering\n",
    "for i in range(1, 16):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(data_normalized)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the WCSS values against the values of k\n",
    "plt.plot(range(1, 16), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the features to use in clustering\n",
    "X = data_normalized.iloc[:, 2:].values\n",
    "\n",
    "# set the number of clusters\n",
    "k = 4\n",
    "\n",
    "# fit the KMeans model\n",
    "kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "y_kmeans = kmeans.fit_predict(X)\n",
    "\n",
    "# plot the clusters\n",
    "sns.set_style('whitegrid')\n",
    "sns.scatterplot(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], color='blue', label='Cluster 1')\n",
    "sns.scatterplot(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], color='green', label='Cluster 2')\n",
    "sns.scatterplot(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], color='red', label='Cluster 3')\n",
    "sns.scatterplot(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], color='orange', label='Cluster 4')\n",
    "sns.scatterplot(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], color='black', label='Centroids')\n",
    "plt.title('Crop Yield Clusters')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of clusters (groups) you want to create\n",
    "n_clusters = 4\n",
    "\n",
    "# Create an instance of KMeans with the desired number of clusters\n",
    "kmeans1 = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "\n",
    "# Fit the KMeans model to your scaled crop yield data\n",
    "y1_kmeans = kmeans1.fit(data_normalized.iloc[:, 2:])\n",
    "\n",
    "# Get the labels assigned to each data point (crop) by KMeans\n",
    "labels1 = kmeans1.labels_\n",
    "\n",
    "# Print out the value of all groups\n",
    "for i in range(n_clusters):\n",
    "    group_crops = data_normalized.iloc[:, 1][labels1 == i].tolist()\n",
    "    #print(f\"Group {i}: {group_crops}\")\n",
    "    print(f\"Group {i}: {np.size(group_crops)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the WCSS values\n",
    "wcss_rm = []\n",
    "\n",
    "# Loop over different values of k and perform k-means clustering\n",
    "for i in range(1, 16):\n",
    "    kmeans_rm = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans_rm.fit(dfByRM)\n",
    "    wcss_rm.append(kmeans_rm.inertia_)\n",
    "\n",
    "# Plot the WCSS values against the values of k\n",
    "plt.plot(range(1, 16), wcss_rm)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of clusters (groups) you want to create\n",
    "n_clusters_rm = 4\n",
    "\n",
    "# Create an instance of KMeans with the desired number of clusters\n",
    "kmeans_rm = KMeans(n_clusters=n_clusters_rm, random_state=42)\n",
    "\n",
    "# Fit the KMeans model to your scaled crop yield data\n",
    "y_kmeans_rm = kmeans_rm.fit(dfByRM.iloc[:, 2:])\n",
    "\n",
    "# Get the labels assigned to each data point (crop) by KMeans\n",
    "labels_rm = kmeans_rm.labels_\n",
    "\n",
    "# Print out the value of all groups\n",
    "for i in range(n_clusters_rm):\n",
    "    group_crops = dfByRM.iloc[:, 1][labels_rm == i].tolist()\n",
    "    #print(f\"Group {i}: {group_crops}\")\n",
    "    print(f\"Group {i}: {np.size(group_crops)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
